\section{Introduction}
\label{sec:intro}
In flash-based SSDs, garbage collection (GC) is inevitable because NAND flash 
memory does not support in-place updates.  
Since the efficiency of garbage collection significantly affects  
both the performance and lifetime of SSDs, garbage collection has been extensively 
investigated so that the garbage collection overhead can be reduced
~\cite{GCGreedy, GCVictim, GCTTFlash, HotCold}.  
For example, hot-cold separation techniques are commonly used inside an SSD 
so that quickly invalidated pages are not mixed with long-lived data in the same block.   
For more efficient garbage collection, many techniques also exploit
host-level I/O access characteristics which can be used as useful hints on 
the efficient data separation inside the SSD~\cite{JiTGC, ShadowGC}.

Multi-streamed SSDs provide a special interface mechanism for 
a host system, called streams,  with which data separation decisions 
on the host level can be delivered to SSDs~\cite{T10, MultiStream}.  
When the host system assigns two data $D_1$ and $D_2$ to 
different streams $S_1$ and $S_2$, respectively, a multi-streamed SSD 
places $D_1$ and $D_2$ in different blocks, which belong to S1 and S2, respectively.
When $D_1$ and $D_2$ have distinct update patterns, say, $D_1$ with a short lifetime 
and $D_2$ with a long lifetime, allocating $D_1$ and $D_2$ to different streams 
can be effective in minimizing the copy cost of
garbage collection by separating hot data from cold data.  
When streams are properly managed, they can significantly
improve both the performance and lifetime of 
flash-based SSDs~\cite{MultiStream, Level, FStream, vStream, AutoStream}.

In order to exploit the potential benefit of multi-streamed SSDs, 
a fully automatic management of streams is essential without requiring any 
code changes in applications.  For example, if an
application developer should manage stream allocations {\it manually} for 
a given SSD with $m$ streams, multi-streamed SSDs are difficult to be 
widely employed in practice.   If the application
developer has no expertise on the application's I/O characteristics or 
the underlying file system, it will be quite challenge to allocate streams correctly.   
Furthermore, if stream allocation decisions have some dependence on
the number of available streams (i.e., $m$),  
the same manual procedure should be repeated whenever the number of streams in an SSD changes.
In this paper, we investigate whether a  
{\it fully-automatic} efficient stream management technique is possible
for general I/O workloads which 
needs no code change in applications regardless of multi-streamed SSDs used.

To the best of our knowledge, however, no existing techniques meet our requirements.  
Most existing techniques~\cite{MultiStream, Level, FStream, vStream} require manual work 
in assigning streams at the application level.  For example,  
in both \textsf{\small vStream}~\cite{vStream} and
\textsf{\small ManualStream}~\cite{MultiStream}, it is an application developer's responsibility to assign streams 
to the application's I/O requests.  
\textsf{\small AutoStream}~\cite{AutoStream} is the only known technique
that supports stream management in the kernel level without manual stream allocation.
However, since \textsf{\small AutoStream} predicts data lifetimes using the update frequency 
of the logical block address (LBA), it does not work well with modern append-only workloads 
such as RocksDB~\cite{RocksDB} or Cassandra~\cite{Cassandra}.  
Unlike conventional update workloads where data written to the same LBAs 
often show strong update locality, 
append-only workloads make it impossible to predict data lifetimes 
from LBA characteristics (such as access frequency or access patterns).  

In order to develop an automatic stream management technique that can be applicable 
over general I/O workloads, we argue that stream allocation decisions should be made 
at a higher abstraction level
than the LBA level where different I/O execution 
contexts can be distinguished.  
In this paper, we employ a program context as such a higher-level measure for 
representing an I/O execution context.
A program context~\cite{PC, PC2}, which represents a particular execution path of a program, 
is known to be an effective hint in separating data with different lifetimes~\cite{PCHa}.  
Our proposed technique, \textsf{\small PCStream}, first identifies a program context 
for each write and maps similar program contexts to streams 
using a k-means clustering algorithm.
Since program contexts can be computed during run time, 
\textsf{\small PCStream} does not need any manual code changes.   

By using program contexts as stream allocation units, \textsf{\small PCStream} easily 
supports different I/O workloads regardless of whether it is update-only or append-only.   
Since program contexts focus on the
semantic aspect of I/O execution, not on the low-level details such as 
LBAs and access patterns, \textsf{\small PCStream} does not need to handle different I/O workloads 
with separate techniques.  Furthermore, since
it is impossible that two different execution paths of different programs are identified 
as the same program context, program contexts are virtually unique over all host applications. 

Although many program contexts show that their data lifetimes are 
narrowly distributed, we observed 
that program contexts alone are not sufficient to distinguish data lifetimes.  
For example, when a database app updates its tables, although we can identify 
different program contexts, their data
lifetime distributions may not be accurately predicted because database 
updates tend to occur in a random fashion.  
Such program contexts have rather large variances.
In \textsf{\small PCStream}, 
when such a program context {\it pID} is observed (which was mapped to a stream {\it sID}), 
the long-lived data of {\it pID} are moved to the substream of {\it sID}
during GC.  
The substream prevents the long-lived data of the stream {\it sID} 
from being mixed with future short-lived data of the stream {\it sID}.

When several program contexts have a large variance in their data lifetimes, 
the number of streams increases for supporting substreams.
In order support substreams effectively, we implement a new stream type, 
called internal streams, which can be used for substreams only. 
Unlike normal streams, internal streams can be efficiently
implemented without increasing the SSD resource budget.  
By dedicating internal streams only for substreams, PCStream can handle 
program streams with large variances without consuming valuable normal
streams.

In order to evaluate the effectiveness of \textsf{\small PCStream}, 
we have implemented \textsf{\small PCStream}
in the Linux kernel (ver. 4.5) and 
extended a Samsung PM963 SSD to support internal streams.
Our experimental results show that \textsf{\small PCStream}
can reduce the GC overhead as much as a highly-optimized 
manual stream management technique while requiring no code modification.  
Furthermore, \textsf{\small PCStream} outperformed \textsf{\small AutoStream} 
by reducing the average WAF by 35\%.

The rest of this paper is organized as follows. 
In Section 2, We explain the limitations of existing techniques.
We discuss potential benefit of program context based 
stream management in Section 3.
In Section 4, we introduce the internal stream and discuss its
requirements and benefits.
Section 5 describes 
the design of \textsf{\small PCStream}.
The experimental results are shown in Section 6. 
Finally, we compare our study to related works in Section 7
and conclude in Section 8 with a summary and future work. 

